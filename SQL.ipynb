{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b7e30012-3927-4f19-aef7-71fe86b70dc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:26: SyntaxWarning: invalid escape sequence '\\d'\n",
      "<>:26: SyntaxWarning: invalid escape sequence '\\d'\n",
      "C:\\Users\\manoj\\AppData\\Local\\Temp\\ipykernel_3624\\3864390592.py:26: SyntaxWarning: invalid escape sequence '\\d'\n",
      "  df['Seat_Availability'] = df['Seat_Availability'].str.extract('(\\d+)')\n",
      "C:\\Users\\manoj\\AppData\\Local\\Temp\\ipykernel_3624\\3864390592.py:26: SyntaxWarning: invalid escape sequence '\\d'\n",
      "  df['Seat_Availability'] = df['Seat_Availability'].str.extract('(\\d+)')\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "cannot concatenate object of type '<class 'list'>'; only Series and DataFrame objs are valid",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 22\u001b[0m\n\u001b[0;32m     19\u001b[0m combined_df\u001b[38;5;241m.\u001b[39mto_csv(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbus_routes.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m, index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m     21\u001b[0m id_column \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mSeries(\u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;28mlen\u001b[39m(df) \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m), name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mid\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m---> 22\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconcat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mid_column\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdf\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     23\u001b[0m df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbus_routes.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     25\u001b[0m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPrice\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPrice\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mstr\u001b[38;5;241m.\u001b[39mreplace(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mINR \u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\pandas\\core\\reshape\\concat.py:382\u001b[0m, in \u001b[0;36mconcat\u001b[1;34m(objs, axis, join, ignore_index, keys, levels, names, verify_integrity, sort, copy)\u001b[0m\n\u001b[0;32m    379\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m copy \u001b[38;5;129;01mand\u001b[39;00m using_copy_on_write():\n\u001b[0;32m    380\u001b[0m     copy \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m--> 382\u001b[0m op \u001b[38;5;241m=\u001b[39m \u001b[43m_Concatenator\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    383\u001b[0m \u001b[43m    \u001b[49m\u001b[43mobjs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    384\u001b[0m \u001b[43m    \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    385\u001b[0m \u001b[43m    \u001b[49m\u001b[43mignore_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_index\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    386\u001b[0m \u001b[43m    \u001b[49m\u001b[43mjoin\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    387\u001b[0m \u001b[43m    \u001b[49m\u001b[43mkeys\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkeys\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    388\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlevels\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlevels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    389\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnames\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnames\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    390\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverify_integrity\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverify_integrity\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    391\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    392\u001b[0m \u001b[43m    \u001b[49m\u001b[43msort\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msort\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    393\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    395\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m op\u001b[38;5;241m.\u001b[39mget_result()\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\pandas\\core\\reshape\\concat.py:448\u001b[0m, in \u001b[0;36m_Concatenator.__init__\u001b[1;34m(self, objs, axis, join, keys, levels, names, ignore_index, verify_integrity, copy, sort)\u001b[0m\n\u001b[0;32m    445\u001b[0m objs, keys \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_clean_keys_and_objs(objs, keys)\n\u001b[0;32m    447\u001b[0m \u001b[38;5;66;03m# figure out what our result ndim is going to be\u001b[39;00m\n\u001b[1;32m--> 448\u001b[0m ndims \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_ndims\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobjs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    449\u001b[0m sample, objs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_sample_object(objs, ndims, keys, names, levels)\n\u001b[0;32m    451\u001b[0m \u001b[38;5;66;03m# Standardize axis parameter to int\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\pandas\\core\\reshape\\concat.py:489\u001b[0m, in \u001b[0;36m_Concatenator._get_ndims\u001b[1;34m(self, objs)\u001b[0m\n\u001b[0;32m    484\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(obj, (ABCSeries, ABCDataFrame)):\n\u001b[0;32m    485\u001b[0m         msg \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    486\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcannot concatenate object of type \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(obj)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m; \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    487\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124monly Series and DataFrame objs are valid\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    488\u001b[0m         )\n\u001b[1;32m--> 489\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(msg)\n\u001b[0;32m    491\u001b[0m     ndims\u001b[38;5;241m.\u001b[39madd(obj\u001b[38;5;241m.\u001b[39mndim)\n\u001b[0;32m    492\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m ndims\n",
      "\u001b[1;31mTypeError\u001b[0m: cannot concatenate object of type '<class 'list'>'; only Series and DataFrame objs are valid"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from mysql import connector\n",
    "\n",
    "df = pd.read_csv(\"ap_bus_details.csv\")\n",
    "df = pd.read_csv(\"telengana_bus_details.csv\")\n",
    "df = pd.read_csv(\"kerala_bus_details.csv\")\n",
    "df = pd.read_csv(\"south_bengal_bus_details.csv\")\n",
    "df = pd.read_csv(\"bihar_bus_details.csv\")\n",
    "df = pd.read_csv(\"himachal_pradesh_bus_details.csv\")\n",
    "df = pd.read_csv(\"rajasthan_bus_details.csv\")\n",
    "df = pd.read_csv(\"punjab_bus_details.csv\")\n",
    "df = pd.read_csv(\"assam_bus_details.csv\")\n",
    "df = pd.read_csv(\"goa_bus_details.csv\")\n",
    "\n",
    "csv_files = [\"ap_bus_details.csv\", \"telengana_bus_details.csv\", \"kerala_bus_details.csv\", \"south_bengal_bus_details.csv\", \"bihar_bus_details.csv\", \"himachal_pradesh_bus_details.csv\", \"rajasthan_bus_details.csv\" , \"punjab_bus_details.csv\", \"assam_bus_details.csv\" , \"goa_bus_details.csv\"]\n",
    "df = [pd.read_csv(file) for file in csv_files]\n",
    "\n",
    "combined_df = pd.concat(df, ignore_index=True)\n",
    "combined_df.to_csv(\"bus_routes.csv\", index=False)\n",
    "\n",
    "id_column = pd.Series(range(1, len(df) + 1), name='id')\n",
    "df = pd.concat([id_column, df], axis=1)\n",
    "df = pd.read_csv(\"bus_routes.csv\")\n",
    "\n",
    "df['Price'] = df['Price'].str.replace('INR ', '')\n",
    "df['Seat_Availability'] = df['Seat_Availability'].str.extract('(\\d+)')\n",
    "\n",
    "myconnection=connector.connect(\n",
    "    host='localhost',\n",
    "    user='root',\n",
    "    password='123456789',\n",
    "    database='redbus'\n",
    ")\n",
    "\n",
    "df = pd.read_csv(\"bus_routes.csv\")\n",
    "df = df.dropna() #drop null values\n",
    "a = \",\".join(f\"{i} {j}\"\n",
    "for i,j in zip(df.columns,df.dtypes)).replace(\"float64\",\"float\").replace(\"object\",\"text\").replace(\"int64\",\"int\")\n",
    "table_name = \"bus_routes\"\n",
    "myconnection.cursor().execute(f\"create table {table_name} ({a})\")\n",
    "for i in range(len(df)):\n",
    "    myconnection.cursor().execute(f\"insert into {table_name} values {tuple(df.iloc[i])}\")\n",
    "    myconnection.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4b630474-82c9-415d-a20d-35c5ce201efa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Table `bus_routes` created successfully!\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from mysql import connector\n",
    "\n",
    "csv_files = [\n",
    "    \"ap_bus_details.csv\", \"telengana_bus_details.csv\", \"kerala_bus_details.csv\",\n",
    "    \"south_bengal_bus_details.csv\", \"bihar_bus_details.csv\",\n",
    "    \"himachal_pradesh_bus_details.csv\", \"rajasthan_bus_details.csv\",\n",
    "    \"punjab_bus_details.csv\", \"assam_bus_details.csv\", \"goa_bus_details.csv\"\n",
    "]\n",
    "\n",
    "dataframes = []\n",
    "for file in csv_files:\n",
    "    try:\n",
    "        df = pd.read_csv(file)\n",
    "        df['Price'] = df['Price'].str.replace('INR ', '', regex=False)\n",
    "        df['Seat_Availability'] = df['Seat_Availability'].str.extract(r'(\\d+)', expand=False)\n",
    "        dataframes.append(df)\n",
    "    except Exception as e:\n",
    "        print(f\"Error reading {file}: {e}\")\n",
    "\n",
    "combined_df = pd.concat(dataframes, ignore_index=True)\n",
    "combined_df.drop_duplicates(inplace=True)\n",
    "combined_df.dropna(inplace=True) \n",
    "\n",
    "\n",
    "combined_df.rename(columns={\n",
    "    'Route_Name': 'route_name',\n",
    "    'Route_Link': 'route_link',\n",
    "    'Bus_Name': 'busname',\n",
    "    'Bus_Type': 'bustype',\n",
    "    'Departing_Time': 'departing_time',\n",
    "    'Duration': 'duration',\n",
    "    'Reaching_Time': 'reaching_time',\n",
    "    'Star_Rating': 'star_rating',\n",
    "    'Price': 'price',\n",
    "    'Seat_Availability': 'seat_availability'\n",
    "}, inplace=True)\n",
    "\n",
    "combined_df['price'] = pd.to_numeric(combined_df['price'], errors='coerce')\n",
    "combined_df['seat_availability'] = pd.to_numeric(combined_df['seat_availability'], errors='coerce').fillna(0).astype(int)\n",
    "\n",
    "myconnection = connector.connect(\n",
    "        host='localhost',\n",
    "        user='root',\n",
    "        password='123456789',\n",
    "        database='redbus'\n",
    "    )\n",
    "cursor = myconnection.cursor()\n",
    "\n",
    "create_table_query = \"\"\"\n",
    "    CREATE TABLE IF NOT EXISTS bus_routes (\n",
    "        id INT AUTO_INCREMENT PRIMARY KEY,\n",
    "        route_name TEXT,\n",
    "        route_link TEXT,\n",
    "        busname TEXT,\n",
    "        bustype TEXT,\n",
    "        departing_time TIME,\n",
    "        duration TEXT,\n",
    "        reaching_time TIME,\n",
    "        star_rating FLOAT,\n",
    "        price DECIMAL(10, 2),\n",
    "        seat_availability INT\n",
    "    );\n",
    "    \"\"\"\n",
    "cursor.execute(create_table_query)\n",
    "print(\"Table `bus_routes` created successfully!\")\n",
    "\n",
    "try:\n",
    "    data = [tuple(row) for row in combined_df.to_numpy()]\n",
    "    placeholders = \", \".join([\"%s\"] * len(combined_df.columns))\n",
    "    insert_query = f\"INSERT INTO bus_routes ({', '.join(combined_df.columns)}) VALUES ({placeholders})\"\n",
    "\n",
    "    cursor.executemany(insert_query, data)\n",
    "    myconnection.commit()\n",
    "\n",
    "except connector.Error as e:\n",
    "    print(f\"Error inserting data: {e}\")\n",
    "    \n",
    "cursor.close()\n",
    "myconnection.close()\n",
    "\n",
    "print('Done!')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b64db8b-122c-483c-a2e6-e7015a85a628",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
